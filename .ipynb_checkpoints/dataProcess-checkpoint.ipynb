{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "import pandas as pd\n",
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "##### This script is to clean and organize data being used for characterization of city scaling properties\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# run parameteres\n",
    "# set true if you're just creating an initial empty dataFile\n",
    "createEmptyData = False\n",
    "\n",
    "# update dataFile cityNames from one file to another\n",
    "updateCityNames = False\n",
    "# file with most up-to-date city names\n",
    "fUpdated = \"Features2013_2016.xls\"\n",
    "# file to be updated\n",
    "fToUpdate = \"Features2000_2005.xls\"\n",
    "\n",
    "# If multiple years are selected, the values are averaged into the output NOTE: 2015 and 2016 are only years with inequality data\n",
    "years = [\"2000\",\"2001\",\"2002\",\"2003\",\"2004\",\"2005\"]\n",
    "# filenames of data source being cleaned, input\n",
    "fIn_Data = \"Data/EuroStatEmployment.xlsx\"\n",
    "# filename of country-cities mapping sheet NOTE: Not updated\n",
    "fIn_countryCities = \"CountryCities\"\n",
    "## Specifications for input datafile\n",
    "# what does the spreadsheet label as cities? (e.g. METROREG/TIME)\n",
    "cityLabel = 'cities Name'\n",
    "# what does the spreadsheet label as feature types (e.g. Variables Name)\n",
    "featLabel = 'indic_ur Name'\n",
    "# what does the spreadsheet label as country names (e.g. Metropolitan Areas -> US)\n",
    "countryLabel = \"cities\"\n",
    "extra_label = True # False, unless filtering on an additional label besides country and city names\n",
    "# map features to their type labels in data TODO: allow for selection of features to update\n",
    "featTypeLabels = {\n",
    "   #'':'Air Traffic'\n",
    "   'Total employment/jobs (work place based)':'Total Employed'\n",
    "\n",
    "     #'Connectivity (normalized)':'Global Firm Presence (without Connectivity)'\n",
    "#    'Population, All ages. Administrative data':'Population',\n",
    "#    'GDP (Millions USD, constant prices, constant PPP, base year 2010)':'GDP',\n",
    "#    'Disposable Income per equivalised household (in USD constant prices, constant PPP, base year 2010)':'Disposable Income per Household',\n",
    "#    'Gini (at disposable income, after taxes and transfers)':'Gini Index',\n",
    "#    'Unemployment (15 years old and over)':'Unemployment',\n",
    "#    'Poverty rate after taxes and transfers, Poverty line 60%':'Poverty Rate',\n",
    "#    'Air Pollution in PM2.5 (average level in µg/m³ experienced by the population)':'Air Pollution'\n",
    "}\n",
    "# if you want to remove features existing in fOut, write their column names here\n",
    "removeFeats = []\n",
    "\n",
    "# some variables, when being compiled into joint MAs, should be added, while some should be averaged, etc\n",
    "def compileCities(dPrior,dNew,feat):\n",
    "    if feat==\"Connectivity\" or feat==\"Air Pollution\" or feat==\"Disposable Income per Household\" or feat=='Gini Index' or feat==\"Poverty Rate\":\n",
    "        return np.average([dPrior,dNew])\n",
    "    elif feat ==\"GDP\" or feat==\"Population\" or feat==\"Unemployment\" or feat==\"Air Traffic\":\n",
    "        return dPrior + dNew\n",
    "    \n",
    "\n",
    "# filename of data source to be added to\n",
    "fOut = \"Features2000_2005.xls\"\n",
    "# if True, include cities in the input dataset that are NOT in the old (compiled) dataset\n",
    "addPartialData = False #TODO: Will this work as false? Was True before\n",
    "# list of countries to include. Either write \"ALL\" or give a list\n",
    "includeCountries = ['ALL'] \n",
    "# cities to exclude due to aggregation into collective MAs.\n",
    "excludeCities = []\n",
    "# set to true if you want to overwrite the data already in fOut TODO\n",
    "overwriteData = True\n",
    "# set true if you're running on a Knomea Dataset\n",
    "KnoemaRun = True\n",
    "# set true if the data you're analyzing is organized by year\n",
    "timeSeries = True\n",
    "\n",
    "\n",
    "countryCodeToCountry = {\n",
    "    'AUS':'Australia',\n",
    "    'AU':'Australia',\n",
    "    'AT':'Austria',\n",
    "    'BE':'Belgium',\n",
    "    'BG':'Bulgaria',\n",
    "    'CAN':'Canada',\n",
    "    'CA':'Canada',\n",
    "    'CH':'Switzerland',\n",
    "    'CL':'Chile',\n",
    "    'COL':'Colombia',\n",
    "    'CZ':'Czech Republic',\n",
    "    'DE':'Germany',\n",
    "    'DEA':'Germany',\n",
    "    'DK':'Denmark',\n",
    "    'ES':'Spain',\n",
    "    'EE':'Estonia',\n",
    "    'FI':'Finland',\n",
    "    'FR':'France',\n",
    "    'NL':\"Netherlands\",\n",
    "    'UK':'United Kingdom',\n",
    "    'EL':'Greece',\n",
    "    'HU':'Hungary',\n",
    "    'HR':'Croatia',\n",
    "    'CY':'Cyprus',\n",
    "    'IE':'Ireland',\n",
    "    'IS':'Iceland',\n",
    "    'IT':'Italy',\n",
    "    'JP':'Japan',\n",
    "    'KR':'Korea',\n",
    "    'JPN':'Japan',\n",
    "    'KOR':'Korea',\n",
    "    'LT':'Lithuania',\n",
    "    'LU':'Luxembourg',\n",
    "    'LV':'Latvia',\n",
    "    'MEX':'Mexico',\n",
    "    'ME':'Mexico',\n",
    "    'MT':'Malta',\n",
    "    'NO':'Norway',\n",
    "    'PL':'Poland',\n",
    "    'PT':'Portugal',\n",
    "    'SK':'Slovakia',\n",
    "    'SI':'Slovenia',\n",
    "    'SE':'Sweden',\n",
    "    'TR':\"Turkey\",\n",
    "    'RO':\"Romania\",\n",
    "    'USA':'United States',\n",
    "    'US':'United States'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-9cef50ecf516>, line 130)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-9cef50ecf516>\"\u001b[0;36m, line \u001b[0;32m130\u001b[0m\n\u001b[0;31m    if\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def getCountryFromCode(countryCode):\n",
    "    m = re.search('[A-Z]+',countryCode)\n",
    "    return countryCodeToCountry[m.group(0)[0:2]]\n",
    "\n",
    "\n",
    "# How to parse the years of data for a given city\n",
    "def merge(row):\n",
    "    rowL = list(row)\n",
    "    for elem in row:\n",
    "        # The   ':' character means no available data, so we remove it\n",
    "        if not hasData(elem):\n",
    "            rowL.remove(elem)\n",
    "            if(rowL == None):\n",
    "                return np.nan\n",
    "    # if there's no available data for that city, return NaN\n",
    "    if rowL == None or len(rowL) == 0: return np.nan\n",
    "    # otherwise, return the average after converting to float\n",
    "    else: \n",
    "        rowL = list(map(lambda x: float(x),rowL))\n",
    "        return np.average(rowL)\n",
    "\n",
    "\n",
    "def hasData(dat):\n",
    "    return not (isinstance(dat,str) or np.isnan(dat))# or isinstance(dat,int) or isinstance(dat,float))\n",
    "\n",
    "\n",
    "# 2) once a match is found, update that country's data frame with that city's info\n",
    "#     - if an entry for that city and property already exists, add the values\n",
    "#     - Otherwise, update data\n",
    "def updateFromRow(outData,loggedCityName,inRow,inCityName,country,foundMatch):\n",
    "    retData = outData\n",
    "    if extra_label:\n",
    "        inRow = inRow.drop(\"extra_label\")\n",
    "\n",
    "    # if the city is not already in the country, add it here, with \"UNKNOWN\" tag\n",
    "    if not foundMatch:\n",
    "        if KnoemaRun:\n",
    "            inRow = inRow.rename({'Country':'UNKNOWN?'})\n",
    "            inRow['UNKNOWN?'] = \"UNKNOWN\"\n",
    "            retData[country] = retData[country].append(inRow)\n",
    "        else:\n",
    "            retData[\"UNKNOWN\"] = retData[\"UNKNOWN\"].append(inRow)\n",
    "        return retData\n",
    "    feats = list(inRow.index)\n",
    "    if KnoemaRun:\n",
    "        feats.remove(\"Country\")\n",
    "    for feat in feats:\n",
    "        #if the data is already included in the output dataset, add to the already existing city entry\n",
    "        if not np.isnan(retData[country][feat][loggedCityName]):\n",
    "            print(\"adding \"+inCityName+\" to \"+loggedCityName)\n",
    "            retData[country][feat][loggedCityName] = compileCities(retData[country][feat][loggedCityName], inRow[feat], feat)\n",
    "        #otherwise, just add it as a new city entry\n",
    "        else:\n",
    "            retData[country][feat][loggedCityName] = inRow[feat]\n",
    "    return retData\n",
    "\n",
    "\n",
    "# do not include cityEntries that are:\n",
    "# Null\n",
    "# \"Non-metropolitan areas\"\n",
    "# empty entries (\":\" or \"Special\")\n",
    "# National Average values\n",
    "# \"UNKNOWN\", as designated in airport-city conversions in function citiesFromAirports\n",
    "def filterCity(cityName):\n",
    "    return not cityName == cityName or \"Non-metropolitan\" in cityName or ':' in cityName or \"Special\" in cityName or \" - \" in cityName or \"National Average\" in cityName\n",
    "\n",
    "# TODO: Finish manually cleaning the excel sheet. NEED TO GO THROUGH MORE THOROUGHLY. \n",
    "# Look into Pau/Tarbes to see how the Metropolitan Areas are defined\n",
    "# From there, go through each entry to carefully categorize the airports. While doing so,\n",
    "# make it extendable in the countryCities spreadsheet so I NEVER have to repeat this later\n",
    "\n",
    "# manual mappings for weird inputs\n",
    "airportCityMappings = {\n",
    "    \"LONDON HEATHROW\": \"London\",\n",
    "    \"LONDON GATWICK\": \"London\",\n",
    "    \"LONDON STANSTED\": \"London\",\n",
    "    \"LYON SAINT-EXUPERY\": \"Lyon\",\n",
    "    \"NANTES ATLANTIQUE\":\"Nantes\",\n",
    "    \"LEEDS BRADFORD\":\"Leeds\",\n",
    "    \"BEOGRAD/NIKOLA TESLA\":\"Belgrade\",\n",
    "    \"MONTPELLIER MEDITERRANEE\":\"Montpellier\",\n",
    "    \"PARIS system\":\"Paris\"\n",
    "}\n",
    "\n",
    "# given airport, the name of an airport-city pair, return the city that airport is in\n",
    "def cityFromAirport(airport):\n",
    "    if \"Unknown airport\" in airport or \"Other airport\" in airport:\n",
    "        return \"UNKNOWN\"\n",
    "    else:\n",
    "        airport = airport.replace(\" airport\",\"\").replace(\"/INTL\",\"\").replace(\"/INTERNATIONAL\",\"\")\n",
    "        if airport in airportCityMappings.keys():\n",
    "            print(\"caught {}, turning into {}\".format(airport, airportCityMappings[airport]))\n",
    "            return airportCityMappings[airport]\n",
    "        else:\n",
    "            return airport\n",
    "        #TODO: Double check\n",
    "\n",
    "# airportData: list of city-airport labels from Eurostat dataset of city air traffic, e.g. \"PRAHA/RUZYNE airport\"\n",
    "# returns the data with renamed indices\n",
    "def citiesFromAirports(airportData):\n",
    "    retData = airportData\n",
    "    for airportName in list(airportData.index):\n",
    "        cityName = cityFromAirport(airportName)\n",
    "        if \"UNKNOWN\" in cityName and airportName in list(retData.index):\n",
    "                retData = retData.drop(airportName)\n",
    "        # merge if the cityName already exists\n",
    "        elif cityName in list(retData.index):\n",
    "            print(cityName)\n",
    "            retData.loc[cityName] = retData.loc[cityName] + airportData.loc[airportName]\n",
    "            if airportName in list(retData.index):\n",
    "                retData = retData.drop(airportName)\n",
    "        else:\n",
    "            retData = retData.rename(index={airportName:cityName})\n",
    "    return retData\n",
    "\n",
    "# split all cities in rawData into their respective countries\n",
    "def splitCountries(rawDataIn,outData,feat=''):\n",
    "    # map: countryName -> Dataframe of cities in that country\n",
    "    countryTables = outData\n",
    "    rawData = rawDataIn\n",
    "\n",
    "    # airport names have to be renamed to their respective cities \n",
    "    if \"Air Traffic\" in feat:\n",
    "        rawData = rawData.dropna(how='all')\n",
    "        rawData = citiesFromAirports(rawData)\n",
    "\n",
    "    for cityName in list(rawData.index):\n",
    "        match = False\n",
    "        for country in list(countryTables.keys()):\n",
    "            if \n",
    "            for loggedCityName in list(countryTables[country].index):\n",
    "                # if the cities match, do the following:\n",
    "                if cityNameMatch(cityName,loggedCityName):\n",
    "                    match = True    \n",
    "                    countryTables = updateFromRow(countryTables,loggedCityName,rawData.loc[cityName],cityName,country,match)\n",
    "                    break\n",
    "\n",
    "            if(match): break\n",
    "        if not match:\n",
    "            countryTables = updateFromRow(countryTables,cityName,rawData.loc[cityName],cityName,\"UNKNOWN\",match)\n",
    "\n",
    "    return countryTables\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# determine if two cities, with names potentially spelled differently and/or \n",
    "# in different languages, are the same cities. Cities with more than one way \n",
    "# of spelling will have them separated by '/'\n",
    "def cityNameMatch(name1,name2):\n",
    "    if \"Non-metroplitan regions in\" in name1 or \"Non-metroplitan regions in\" in name2:\n",
    "        return False\n",
    "    newNames = []\n",
    "    for name in [name1,name2]:\n",
    "        newName = name.lower()\n",
    "        newName = newName.replace(\"(nuts 2010)\",\"\")\n",
    "        newName = newName.replace(\"greater \",\"\")\n",
    "        newName = newName.replace(\" (greater)\",\"\")\n",
    "        newNameList = re.split('/|-',newName)\n",
    "        newNames.append(newNameList)\n",
    "        \n",
    "    name1List = newNames[0]\n",
    "    name2List = newNames[1]\n",
    "    for subName1 in name1List:\n",
    "        for subName2 in name2List:\n",
    "            #if (subName1 in subName2 or subName2 in subName1) and not subName1.strip() == subName2.strip():\n",
    "            #    print(\"edge case matching - %s , %s\", (subName1, subName2))\n",
    "            #if (subName1 in subName2) or (subName2 in subName1):\n",
    "            if subName1.strip() == subName2.strip():\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# read countryCities from fOut\n",
    "fOutData = pd.ExcelFile(fOut)\n",
    "\n",
    "allCountries = fOutData.sheet_names  # see all sheet names\n",
    "\n",
    "if 'ALL' in includeCountries[0]:\n",
    "    includeCountries = allCountries\n",
    "\n",
    "\n",
    "### update city names\n",
    "if updateCityNames:\n",
    "    updatedData = {}\n",
    "    toUpdateData = {}\n",
    "    for country in allCountries:\n",
    "        if country in \"UNKNOWN\":\n",
    "            continue\n",
    "\n",
    "        updatedData[country] = pd.read_excel(fUpdated,sheet_name=country).set_index(cityLabel)\n",
    "        toUpdateData[country] = pd.read_excel(fToUpdate,sheet_name=country).set_index(cityLabel)\n",
    "\n",
    "        updatedCityNames = list(updatedData[country].index)\n",
    "        toUpdateCityNames = list(toUpdateData[country].index)\n",
    "\n",
    "        toUpdateData[country] = toUpdateData[country].rename(index=dict(zip(toUpdateCityNames,updatedCityNames)))\n",
    "\n",
    "        # for testing\n",
    "        fToUpdateTest = \"testUpdate.xls\"\n",
    "\n",
    "\n",
    "\n",
    "    with pd.ExcelWriter(fToUpdate) as writer:\n",
    "        for country in allCountries:\n",
    "            if not country in \"UNKNOWN\":\n",
    "                toUpdateData[country].to_excel(writer,sheet_name=country)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### create empty output \n",
    "if createEmptyData:\n",
    "    # this will be eventually printed as output\n",
    "    # map: countryname to dataframe\n",
    "    emptyData = {}\n",
    "    countryCities = pd.read_excel(fIn_countryCities)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # separate countryCities into different countries\n",
    "    for country in includeCountries:\n",
    "        emptyData[country] = pd.DataFrame(countryCities[country].dropna())\n",
    "        emptyData[country] = emptyData[country].rename({country:'City'},axis='columns')\n",
    "        #emptyData[country] = emptyData[country].set_index(country)\n",
    "    # create output file with just cities, no data\n",
    "    \n",
    "    with  pd.ExcelWriter(fOut) as writer:\n",
    "        for country in emptyData:\n",
    "            emptyData[country].to_excel(writer, sheet_name=country,index=False)\n",
    "        \n",
    "\n",
    "if not updateCityNames:\n",
    "    # start with (and later add to) existing dataframe from Features.xls\n",
    "    outData = {}\n",
    "    iterCountries = list(includeCountries)\n",
    "    if \"UNKNOWN\" in iterCountries:\n",
    "        iterCountries.remove(\"UNKNOWN\")\n",
    "\n",
    "    for country in iterCountries:\n",
    "        # TODO: Is setting index necessary? Will be different when starting vs updating\n",
    "        outData[country] = pd.read_excel(fOut,sheet_name=country).set_index('City')\n",
    "\n",
    "        # drop nan-index entries\n",
    "        outData[country] = outData[country][outData[country].index.notnull()]\n",
    "\n",
    "        # update with empty columns for new features\n",
    "        for feat in featTypeLabels.values():\n",
    "            # if overwriting, set existing data to NaN. If there's not data there, add empty column\n",
    "            # TODO: move this to later stage, probably updateFromRow, so that entries that ARE NOT being updated \n",
    "            # are left alone (need extra parameter to hard overwrite everything)\n",
    "            if (feat in outData[country].columns and overwriteData) or (feat not in outData[country].columns):\n",
    "                outData[country][feat] = np.nan\n",
    "        \n",
    "        # remove features as specified above\n",
    "        try:\n",
    "            outData[country] = outData[country].drop(columns=removeFeats)\n",
    "        except KeyError:\n",
    "            print(\"WARNING: Attempting to remove feature(s) that are not in the dataset: \"+str(removeFeats))\n",
    "            continue\n",
    "\n",
    "    # standard processing for most datasets\n",
    "    if not KnoemaRun:\n",
    "        # add unknown as new sheet for non-country-marked data (not Knoema)\n",
    "        columns = featTypeLabels.values()\n",
    "        outData[\"UNKNOWN\"] = pd.DataFrame(columns = columns)\n",
    "        dtypes = {cityLabel:str}\n",
    "\n",
    "        # open input file, merging arrivals and departures for air traffic\n",
    "        # TODO: Go back and make this work, combining arrivals and departures\n",
    "        #if \"Air Traffic\" in feat:\n",
    "        #    arrivals = pd.read_excel(fIn_Data,dtype=dtypes,sheet_name=\"EUArrivals\")\n",
    "        #    arrivals = arrivals.set_index(cityLabel)\n",
    "        #    departures = pd.read_excel(fIn_Data,dtype=dtypes,sheet_name=\"EUDepartures\")\n",
    "        #    departures = departures.set_index(cityLabel)\n",
    "        #    inDataRaw = (arrivals + departures)/2\n",
    "        #else:\n",
    "        #    inDataRaw = pd.read_excel(fIn_Data,dtype=dtypes)   \n",
    "        #    inDataRaw = inDataRaw.set_index(cityLabel)\n",
    "        if \"Air Traffic\" in feat:\n",
    "            inDataRaw = pd.read_excel(fIn_Data,dtype=dtypes,sheet_name=\"EUArrivals\")\n",
    "        else:\n",
    "            inDataRaw = pd.read_excel(fIn_Data,dtype=dtypes)   \n",
    "        inDataRaw = inDataRaw.set_index(cityLabel)\n",
    "\n",
    "        if timeSeries:\n",
    "        # combine different years of Data\n",
    "            for feat in list(featTypeLabels.values()):\n",
    "                inDataRaw[feat] = inDataRaw[years].apply(merge, axis=1)\n",
    "            inDataRaw = inDataRaw[list(featTypeLabels.values())]\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "        inDataRaw = inDataRaw.rename(columns=featTypeLabels)\n",
    "                \n",
    "                #merge only selected years of data for EuroStat data \n",
    "\n",
    "\n",
    "        #TODO: I don't think this needs to iterate over features; should run one time, with upDateFromRow\n",
    "        # properly moving all data over \n",
    "        for featLbl in list(featTypeLabels.keys()):\n",
    "            feat = featTypeLabels[featLbl]\n",
    "\n",
    "            # split raw input into countries\n",
    "            # inData: map: country name -> dataframe\n",
    "            outData = splitCountries(inDataRaw,outData,feat=feat)\n",
    "\n",
    "\n",
    "\n",
    "    # TODO: Tokyo Population HUGE\n",
    "    # different processing for Knomean datasets\n",
    "    elif KnoemaRun: \n",
    "        ### process data into one dataframe matching city-indices with country and properties\n",
    "        inDataRaw = pd.read_excel(fIn_Data,dtypes={cityLabel:str,countryLabel:str,featLabel:str})\n",
    "        inDataRaw = inDataRaw.set_index(cityLabel)\n",
    "\n",
    "        # set indices and columns for inData\n",
    "        cities = []\n",
    "        for city in list(inDataRaw.index):\n",
    "            if city not in cities:\n",
    "                cities.append(city)\n",
    "        if extra_label:\n",
    "            columns = [\"Country\",\"extra_label\"] + list(featTypeLabels.values())\n",
    "        else:\n",
    "            columns = [\"Country\"] + list(featTypeLabels.values())\n",
    "       \n",
    "        inData = pd.DataFrame(index=cities,columns=columns)\n",
    "        for cityName,rawDataRow in inDataRaw.iterrows():\n",
    "            country = getCountryFromCode(rawDataRow[countryLabel])\n",
    "            if extra_label:\n",
    "                extra_label = rawDataRow[\"cities\"]\n",
    "                        \n",
    "            # the feature name as named in the input datafile\n",
    "            feat = rawDataRow[featLabel]\n",
    "            # calculate feature value from average over years\n",
    "            featList = []\n",
    "            for year in years:\n",
    "                featList.append(rawDataRow[year])\n",
    "            featVal = merge(featList)\n",
    "            # update inData \n",
    "            inData[featTypeLabels[feat]][cityName]=featVal\n",
    "            inData[\"Country\"][cityName] = country\n",
    "            if extra_label:\n",
    "                inData[\"extra_label\"][cityName] = extra_label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ### reformat city indicies/entries into standardized format\n",
    "        # iterate over every row in the dataframe, doing the following:\n",
    "        # 1) find a match for the cityName\n",
    "        #     - if no match exists, add it to \"unmatched\" output\n",
    "        # 2) once a match is found, update that country's data frame with that city's info\n",
    "        #     - if an entry for that city and property already exists, add the values\n",
    "        for cityName, cityData in inData.iterrows():\n",
    "            foundMatch = False\n",
    "            country = cityData[\"Country\"]\n",
    "            is_proper_city = True\n",
    "            if extra_label:\n",
    "                if cityData[\"extra_label\"] == 2:\n",
    "                    is_proper_city = False\n",
    "                    print(\"REJECTED\",cityName)\n",
    "                elif cityData[\"extra_label\"][-2:] == \"K1\":\n",
    "                    is_proper_city = False\n",
    "                    print(\"REJECTED\",cityName)\n",
    "                set_trace()\n",
    "                if country not in outData.columns:\n",
    "                    is_proper_city = False\n",
    "                    print(\"REJECTED (via Country)\",cityName,country)\n",
    "\n",
    "            # 1) find a match for the cityName\n",
    "            for loggedCityName in list(outData[country].index):\n",
    "                # check for matches with outData\n",
    "                # skip over cities to be excluded here\n",
    "\n",
    "                        \n",
    "                                                        \n",
    "                if cityNameMatch(cityName,loggedCityName) and not city in excludeCities and is_proper_city:\n",
    "                    # 2) once a match is found, update that country's data frame with that city's info\n",
    "                    #     - if an entry for that city and property already exists, add the values\n",
    "                    #     - Otherwise, update data\n",
    "                    foundMatch = True\n",
    "                    print(\"adding data\")\n",
    "                    outData = updateFromRow(outData,loggedCityName,cityData,cityName,country,foundMatch)\n",
    "                    break\n",
    "            # if no match exists, add it to \"unmatched\" output\n",
    "            if not foundMatch:\n",
    "                outData = updateFromRow(outData,cityName,cityData,cityName,country,foundMatch)\n",
    "\n",
    "\n",
    "    # write each country data to dif\n",
    "    # ferent sheets in output\n",
    "    with pd.ExcelWriter(\"newFeatures.xls\") as writer:\n",
    "        for country in outData:\n",
    "            outData[country].to_excel(writer, sheet_name=country)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
